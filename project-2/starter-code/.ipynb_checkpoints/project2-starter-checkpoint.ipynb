{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2\n",
    "\n",
    "In this project, you will implement the exploratory analysis plan developed in Project 1. This will lay the groundwork for our our first modeling exercise in Project 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the python libraries you will need for this project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Read in your data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   admit    gre   gpa  prestige\n",
      "0      0  380.0  3.61       3.0\n",
      "1      1  660.0  3.67       3.0\n",
      "2      1  800.0  4.00       1.0\n",
      "3      1  640.0  3.19       4.0\n",
      "4      0  520.0  2.93       4.0\n"
     ]
    }
   ],
   "source": [
    "#Read in data from source \n",
    "df_raw = pd.read_csv(\"../assets/admissions.csv\")\n",
    "print df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "#### Question 1. How many observations are in our dataset? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit       400\n",
       "gre         398\n",
       "gpa         398\n",
       "prestige    399\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2. Create a summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.00000</td>\n",
       "      <td>399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317500</td>\n",
       "      <td>588.040201</td>\n",
       "      <td>3.39093</td>\n",
       "      <td>2.486216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466087</td>\n",
       "      <td>115.628513</td>\n",
       "      <td>0.38063</td>\n",
       "      <td>0.945333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.26000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.13000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.39500</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.67000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre        gpa    prestige\n",
       "count  400.000000  398.000000  398.00000  399.000000\n",
       "mean     0.317500  588.040201    3.39093    2.486216\n",
       "std      0.466087  115.628513    0.38063    0.945333\n",
       "min      0.000000  220.000000    2.26000    1.000000\n",
       "25%      0.000000  520.000000    3.13000    2.000000\n",
       "50%      0.000000  580.000000    3.39500    2.000000\n",
       "75%      1.000000  660.000000    3.67000    3.000000\n",
       "max      1.000000  800.000000    4.00000    4.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 3. Why would GRE have a larger STD than GPA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The minimum, maximum and mean values are all much bigger. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Question 4. Drop data points with missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>760.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2.98</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.39</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.92</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>760.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.08</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>700.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>480.0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>780.0</td>\n",
       "      <td>3.87</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.81</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>2.82</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>680.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>760.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>3.66</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>520.0</td>\n",
       "      <td>3.74</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>780.0</td>\n",
       "      <td>3.22</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.77</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>1</td>\n",
       "      <td>680.0</td>\n",
       "      <td>3.76</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>1</td>\n",
       "      <td>680.0</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.78</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.49</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.63</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>2.70</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.49</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>1</td>\n",
       "      <td>480.0</td>\n",
       "      <td>2.62</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>1</td>\n",
       "      <td>740.0</td>\n",
       "      <td>3.86</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>0</td>\n",
       "      <td>580.0</td>\n",
       "      <td>3.36</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.17</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>0</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.51</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>3.05</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.88</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.38</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>620.0</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1</td>\n",
       "      <td>460.0</td>\n",
       "      <td>3.99</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit    gre   gpa  prestige\n",
       "0        0  380.0  3.61       3.0\n",
       "1        1  660.0  3.67       3.0\n",
       "2        1  800.0  4.00       1.0\n",
       "3        1  640.0  3.19       4.0\n",
       "4        0  520.0  2.93       4.0\n",
       "5        1  760.0  3.00       2.0\n",
       "6        1  560.0  2.98       1.0\n",
       "7        0  400.0  3.08       2.0\n",
       "8        1  540.0  3.39       3.0\n",
       "9        0  700.0  3.92       2.0\n",
       "10       0  800.0  4.00       4.0\n",
       "11       0  440.0  3.22       1.0\n",
       "12       1  760.0  4.00       1.0\n",
       "13       0  700.0  3.08       2.0\n",
       "14       1  700.0  4.00       1.0\n",
       "15       0  480.0  3.44       3.0\n",
       "16       0  780.0  3.87       4.0\n",
       "17       0  360.0  2.56       3.0\n",
       "18       0  800.0  3.75       2.0\n",
       "19       1  540.0  3.81       1.0\n",
       "20       0  500.0  3.17       3.0\n",
       "21       1  660.0  3.63       2.0\n",
       "22       0  600.0  2.82       4.0\n",
       "23       0  680.0  3.19       4.0\n",
       "24       1  760.0  3.35       2.0\n",
       "25       1  800.0  3.66       1.0\n",
       "26       1  620.0  3.61       1.0\n",
       "27       1  520.0  3.74       4.0\n",
       "28       1  780.0  3.22       2.0\n",
       "29       0  520.0  3.29       1.0\n",
       "..     ...    ...   ...       ...\n",
       "370      1  540.0  3.77       2.0\n",
       "371      1  680.0  3.76       3.0\n",
       "372      1  680.0  2.42       1.0\n",
       "373      1  620.0  3.37       1.0\n",
       "374      0  560.0  3.78       2.0\n",
       "375      0  560.0  3.49       4.0\n",
       "376      0  620.0  3.63       2.0\n",
       "377      1  800.0  4.00       2.0\n",
       "378      0  640.0  3.12       3.0\n",
       "379      0  540.0  2.70       2.0\n",
       "380      0  700.0  3.65       2.0\n",
       "381      1  540.0  3.49       2.0\n",
       "382      0  540.0  3.51       2.0\n",
       "383      0  660.0  4.00       1.0\n",
       "384      1  480.0  2.62       2.0\n",
       "385      0  420.0  3.02       1.0\n",
       "386      1  740.0  3.86       2.0\n",
       "387      0  580.0  3.36       2.0\n",
       "388      0  640.0  3.17       2.0\n",
       "389      0  640.0  3.51       2.0\n",
       "390      1  800.0  3.05       2.0\n",
       "391      1  660.0  3.88       2.0\n",
       "392      1  600.0  3.38       3.0\n",
       "393      1  620.0  3.75       2.0\n",
       "394      1  460.0  3.99       3.0\n",
       "395      0  620.0  4.00       2.0\n",
       "396      0  560.0  3.04       3.0\n",
       "397      0  460.0  2.63       2.0\n",
       "398      0  700.0  3.65       2.0\n",
       "399      0  600.0  3.89       3.0\n",
       "\n",
       "[397 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>398.000000</td>\n",
       "      <td>398.00000</td>\n",
       "      <td>399.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.317500</td>\n",
       "      <td>588.040201</td>\n",
       "      <td>3.39093</td>\n",
       "      <td>2.486216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.466087</td>\n",
       "      <td>115.628513</td>\n",
       "      <td>0.38063</td>\n",
       "      <td>0.945333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>2.26000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>520.000000</td>\n",
       "      <td>3.13000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>580.000000</td>\n",
       "      <td>3.39500</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>660.000000</td>\n",
       "      <td>3.67000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            admit         gre        gpa    prestige\n",
       "count  400.000000  398.000000  398.00000  399.000000\n",
       "mean     0.317500  588.040201    3.39093    2.486216\n",
       "std      0.466087  115.628513    0.38063    0.945333\n",
       "min      0.000000  220.000000    2.26000    1.000000\n",
       "25%      0.000000  520.000000    3.13000    2.000000\n",
       "50%      0.000000  580.000000    3.39500    2.000000\n",
       "75%      1.000000  660.000000    3.67000    3.000000\n",
       "max      1.000000  800.000000    4.00000    4.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#if you drop data above, shouldn't the descriptive stats be different?\n",
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print df_raw['admit'].isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# shouldn't this say 0 since I dropped values previously?\n",
    "print df_raw['gre'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print df_raw['gpa'].isnull().sum()\n",
    "print len(df_raw) - len(df_raw['gpa'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print df_raw['prestige'].isnull().sum()\n",
    "print len(df_raw) - len(df_raw['prestige'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shouldn't the shape be different after dropping values?\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Question 5. Confirm that you dropped the correct data. How can you tell? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 6. Create box plots for GRE and GPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x121125fd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12127e790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#boxplot 1\n",
    "df_raw['gre'].plot(kind=\"box\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1212e54d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEeVJREFUeJzt3X+snnV9//Hny+NxIHSQjBNHKF1dwh9lnYXlrJrZyWq+\nkKIysmzJIM5lrqZhQaOL2+zs9+vili5uJmbbV7emsUTMtMZMmAyKilkXrQbktCvFcmBpGAs0ZD34\no9ANlbL3/rivztuzczj3fc7dnsLn+Uju9Lo/1/u67vf1B6/74nNf17lSVUiS2vGy5W5AknRmGfyS\n1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxrx8uRuYy0UXXVSrV69e7jYk6UVj//79\nT1XVxCC1Z2Xwr169mqmpqeVuQ5JeNJL826C1TvVIUmMMfklqjMEvSY0x+CWpMQa/JDVm4OBPMpbk\nn5PcOce6JPmrJEeSHEryc33rNiV5pFu3dVSNS5IWZ5gz/ncD0/Osuxa4rHttAf4Gel8WwMe69ZcD\nNya5fNHdSpKWbKDgT7ISeDPw8XlKrgc+WT33AhcmuRhYDxypqker6gfAZ7paSdIyGfQGrr8A/gBY\nMc/6S4DH+94/0Y3NNf7auXaQZAu9/1tg1apVA7YlLV6SM/ZZPttaZ5MFz/iTvAU4VlX7T2cjVbWz\nqiaranJiYqC7jqUlqaqhXz/1vjsXtZ10NhnkjP/1wC8neRNwDvDjSf62qn6jr+YocGnf+5Xd2Pg8\n45KkZbLgGX9V/WFVrayq1cANwD/OCn2AO4Df7K7ueR1wvKqeBO4HLkvy6iSv6La/Y7SHIEkaxqL/\nSFuSmwCqagewB3gTcAT4T+Dt3bqTSd4JfBEYA26pqsNLbVqStHhDBX9V/RPwT93yjr7xAm6eZ5s9\n9L4YJElnAe/claTGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+S\nGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhqz4DN3k5wDfAX4sa7+76rqj2bV\n/D7w1r59rgEmqurbSR4DngGeB05W1eTo2pckDWuQh61/H3hjVZ1IMg7sS3J3Vd17qqCqPgx8GCDJ\ndcDvVtW3+/axsaqeGmXjkqTFWTD4q6qAE93b8e5VL7DJjcDupbcmSTodBprjTzKW5CBwDLinqu6b\np+6VwCbgc33DBXw5yf4kW5basCRpaQYK/qp6vqquAFYC65Osnaf0OuBrs6Z5NnTbXgvcnOQNc22Y\nZEuSqSRTMzMzQxyCJGkYQ13VU1XfBfbSO6ufyw3MmuapqqPdv8eA24H18+x7Z1VNVtXkxMTEMG1J\nkoawYPAnmUhyYbd8LnA18PAcdRcAVwGf7xs7L8mKU8vANcA3R9O6JGkxBrmq52Lg1iRj9L4oPltV\ndya5CaCqdnR1vwJ8qar+o2/bVwG3Jzn1WZ+uqi+MrHtJ0tAGuarnEHDlHOM7Zr3/BPCJWWOPAuuW\n1KEkaaS8c1eSGmPwS1JjDH5JaozBL0mNGeSqHulFYd0Hv8TxZ5877Z+zeutdp3X/F5w7zgN/dM1p\n/Qy1zeDXS8bxZ5/jsQ+9ebnbWLLT/cUiOdUjSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1Jj\nDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmAWDP8k5Sb6R5IEkh5N8cI6aX0pyPMnB7vWBvnWb\nkjyS5EiSraM+AEnScAb5s8zfB95YVSeSjAP7ktxdVffOqvtqVb2lfyDJGPAx4GrgCeD+JHdU1UOj\naF6SNLwFz/ir50T3drx71YD7Xw8cqapHq+oHwGeA6xfVqSRpJAaa408yluQgcAy4p6rum6PsF5Ic\nSnJ3kp/pxi4BHu+reaIbkyQtk4GCv6qer6orgJXA+iRrZ5UcAFZV1WuA/w/8/bCNJNmSZCrJ1MzM\nzLCbS5IGNNRVPVX1XWAvsGnW+NOnpoOqag8wnuQi4ChwaV/pym5srn3vrKrJqpqcmJgYpi1J0hAG\nuapnIsmF3fK59H6ofXhWzU8mSbe8vtvvt4D7gcuSvDrJK4AbgDtGewiSpGEMclXPxcCt3RU6LwM+\nW1V3JrkJoKp2AL8G/E6Sk8CzwA1VVcDJJO8EvgiMAbdU1eHTcSCSpMEsGPxVdQi4co7xHX3LHwU+\nOs/2e4A9S+hRkjRC3rkrSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjBrmBS3pRWLFmKz97\n64v/kQ8r1gC8ebnb0EuYwa+XjGemP8RjH3rxB+bqrXctdwt6iXOqR5IaY/BLUmMMfklqjMEvSY0x\n+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JasyCwZ/knCTfSPJAksNJPjhHzVuTHEryYJKv\nJ1nXt+6xbvxgkqlRH4AkaTiD/JG27wNvrKoTScaBfUnurqp7+2r+Fbiqqr6T5FpgJ/DavvUbq+qp\n0bUtSVqsBYO/qgo40b0d7141q+brfW/vBVaOqkFJ0mgNNMefZCzJQeAYcE9V3fcC5ZuBu/veF/Dl\nJPuTbHmBz9iSZCrJ1MzMzCBtSZIWYaDgr6rnq+oKemfy65OsnasuyUZ6wf++vuEN3bbXAjcnecM8\nn7GzqiaranJiYmKog5AkDW6oq3qq6rvAXmDT7HVJXgN8HLi+qr7Vt83R7t9jwO3A+qU0LElamkGu\n6plIcmG3fC5wNfDwrJpVwG3A26rqX/rGz0uy4tQycA3wzdG1L0ka1iBX9VwM3JpkjN4XxWer6s4k\nNwFU1Q7gA8BPAH+dBOBkVU0CrwJu78ZeDny6qr4w+sOQJA1qkKt6DgFXzjG+o2/5HcA75qh5FFg3\ne1yStHy8c1eSGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmEHu3JVeNFZvvWu5W1iy\nC84dX+4W9BJn8Osl47EPvfm0f8bqrXedkc+RTieneiSpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1Jj\nDH5JaozBL0mNMfglqTELBn+Sc5J8I8kDSQ4n+eAcNUnyV0mOJDmU5Of61m1K8ki3buuoD0CSNJxB\nzvi/D7yxqtYBVwCbkrxuVs21wGXdawvwNwBJxoCPdesvB25McvmIepckLcKCwV89J7q3492rZpVd\nD3yyq70XuDDJxcB64EhVPVpVPwA+09VKkpbJQHP8ScaSHASOAfdU1X2zSi4BHu97/0Q3Nt+4JGmZ\nDBT8VfV8VV0BrATWJ1k76kaSbEkylWRqZmZm1LuXJHWGuqqnqr4L7AU2zVp1FLi07/3Kbmy+8bn2\nvbOqJqtqcmJiYpi2JElDGOSqnokkF3bL5wJXAw/PKrsD+M3u6p7XAcer6kngfuCyJK9O8grghq5W\nkrRMBnkQy8XArd0VOi8DPltVdya5CaCqdgB7gDcBR4D/BN7erTuZ5J3AF4Ex4JaqOjz6w5AkDWrB\n4K+qQ8CVc4zv6Fsu4OZ5tt9D74tBknQW8M5dSWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5Ia\nY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEG\nvyQ1ZsGHrSe5FPgk8CqggJ1V9Zezan4feGvfPtcAE1X17SSPAc8AzwMnq2pydO1Lkoa1YPADJ4H3\nVtWBJCuA/UnuqaqHThVU1YeBDwMkuQ743ar6dt8+NlbVU6NsXJK0OAtO9VTVk1V1oFt+BpgGLnmB\nTW4Edo+mPUnSqA01x59kNXAlcN88618JbAI+1zdcwJeT7E+y5QX2vSXJVJKpmZmZYdqSJA1h4OBP\ncj69QH9PVT09T9l1wNdmTfNsqKorgGuBm5O8Ya4Nq2pnVU1W1eTExMSgbUmShjRQ8CcZpxf6n6qq\n216g9AZmTfNU1dHu32PA7cD6xbUqSRqFBYM/SYBdwHRVfeQF6i4ArgI+3zd2XveDMEnOA64BvrnU\npiVJizfIVT2vB94GPJjkYDf2fmAVQFXt6MZ+BfhSVf1H37avAm7vfXfwcuDTVfWFUTQuSVqcBYO/\nqvYBGaDuE8AnZo09CqxbZG+SpNPAO3clqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9J\njTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4JekxiwY/Eku\nTbI3yUNJDid59xw1v5TkeJKD3esDfes2JXkkyZEkW0d9AJKk4Sz4sHXgJPDeqjqQZAWwP8k9VfXQ\nrLqvVtVb+geSjAEfA64GngDuT3LHHNtKks6QBc/4q+rJqjrQLT8DTAOXDLj/9cCRqnq0qn4AfAa4\nfrHNSpKWbqg5/iSrgSuB++ZY/QtJDiW5O8nPdGOXAI/31TzB4F8akqTTYJCpHgCSnA98DnhPVT09\na/UBYFVVnUjyJuDvgcuGaSTJFmALwKpVq4bZVJI0hIHO+JOM0wv9T1XVbbPXV9XTVXWiW94DjCe5\nCDgKXNpXurIb+1+qamdVTVbV5MTExJCHIUka1CBX9QTYBUxX1UfmqfnJro4k67v9fgu4H7gsyauT\nvAK4AbhjVM1LkoY3yFTP64G3AQ8mOdiNvR9YBVBVO4BfA34nyUngWeCGqirgZJJ3Al8ExoBbqurw\niI9BkjSEBYO/qvYBWaDmo8BH51m3B9izqO4kSSPnnbuS1BiDX5IaY/BLUmMMfklqzMA3cEkvNd0V\nyMNv92fDb9O7yE06Oxj8apZhrFY51SNJjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklq\njMEvSY0x+CWpMQa/JDXG4Jekxhj8ktSYBYM/yaVJ9iZ5KMnhJO+eo+atSQ4leTDJ15Os61v3WDd+\nMMnUqA9AOhN2797N2rVrGRsbY+3atezevXu5W5IWbZA/y3wSeG9VHUiyAtif5J6qeqiv5l+Bq6rq\nO0muBXYCr+1bv7Gqnhpd29KZs3v3brZt28auXbvYsGED+/btY/PmzQDceOONy9ydNLwFz/ir6smq\nOtAtPwNMA5fMqvl6VX2ne3svsHLUjUrLZfv27ezatYuNGzcyPj7Oxo0b2bVrF9u3b1/u1qRFGWqO\nP8lq4Ergvhco2wzc3fe+gC8n2Z9ky7ANSsttenqaDRs2/MjYhg0bmJ6eXqaOpKUZOPiTnA98DnhP\nVT09T81GesH/vr7hDVV1BXAtcHOSN8yz7ZYkU0mmZmZmBj4A6XRbs2YN+/bt+5Gxffv2sWbNmmXq\nSFqagYI/yTi90P9UVd02T81rgI8D11fVt06NV9XR7t9jwO3A+rm2r6qdVTVZVZMTExPDHYV0Gm3b\nto3Nmzezd+9ennvuOfbu3cvmzZvZtm3bcrcmLcqCP+6m90TqXcB0VX1knppVwG3A26rqX/rGzwNe\nVlXPdMvXAH88ks6lM+TUD7jvete7mJ6eZs2aNWzfvt0fdvWilYUeOJ1kA/BV4EHgv7rh9wOrAKpq\nR5KPA78K/Fu3/mRVTSb5aXpn+dD7kvl0VS34i9jk5GRNTXnlpyQNKsn+qpocpHbBM/6q2gdkgZp3\nAO+YY/xRYN3/3kKStFy8c1eSGmPwS1JjDH5JaozBL0mNWfCqnuWQZIYfXiEknU0uAvy7Uzob/VRV\nDXQT1FkZ/NLZKsnUoJfMSWcrp3okqTEGvyQ1xuCXhrNzuRuQlso5fklqjGf8ktQYg1+SGmPwS1Jj\nBnnYutSMJP8P+A1gBngc2A+8BXgAuIrefzO/XVXfSLIe+EvgHOBZ4O1V9ciyNC4NweCXOkl+nt5z\nJdYB48ABesEP8MqquqJ7dOgtwFrgYeAXq+pkkv8D/Gm3vXRWM/ilH3o98Pmq+h7wvST/0LduN0BV\nfSXJjye5EFgB3JrkMqDofVlIZz3n+KXBzL7uuYA/AfZW1VrgOnpTPtJZz+CXfuhrwHVJzklyPr25\n/VN+Hf7nUaTHq+o4cAFwtFv/W2eyUWkpnOqROlV1f5I7gEPAv9N7zvTxbvX3kvwzvemc3+7G/pze\nVM//Be460/1Ki+Wdu1KfJOdX1YkkrwS+AmwBPgL8XlVNLW930mh4xi/9qJ1JLqc3X39rVR1Istw9\nSSPlGb8kNcYfdyWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1Jj/huuRIp/DBfUWgAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12142e050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#boxplot 2 \n",
    "df_raw['gpa'].plot(kind=\"box\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 7. What do this plots show?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 8. Describe each distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x122153210>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x121c52ad0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x1220d3710>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x122304310>]], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121c529d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the distribution of each variable \n",
    "df_raw.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "admit       0.787051\n",
       "gre        -0.150127\n",
       "gpa        -0.211765\n",
       "prestige    0.093663\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 9.  If our model had an assumption of a normal distribution would we meet that requirement? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: No, gpa and gre are negatively skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 10.  Does this distribution need correction? If so, why? How? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: It is skewed so you can correct this using log transformation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 11. Which of our variables are potentially colinear? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admit</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.182919</td>\n",
       "      <td>0.175952</td>\n",
       "      <td>-0.241355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gre</th>\n",
       "      <td>0.182919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.382408</td>\n",
       "      <td>-0.124533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpa</th>\n",
       "      <td>0.175952</td>\n",
       "      <td>0.382408</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.059031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige</th>\n",
       "      <td>-0.241355</td>\n",
       "      <td>-0.124533</td>\n",
       "      <td>-0.059031</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             admit       gre       gpa  prestige\n",
       "admit     1.000000  0.182919  0.175952 -0.241355\n",
       "gre       0.182919  1.000000  0.382408 -0.124533\n",
       "gpa       0.175952  0.382408  1.000000 -0.059031\n",
       "prestige -0.241355 -0.124533 -0.059031  1.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a correlation matrix for the data\n",
    "df_raw.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 12. What did you find?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 13. Write an analysis plan for exploring the association between grad school admissions rates and prestige of  undergraduate schools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Create dummy variables for the prestige column using get_dummies with 4 levels. Get rid of the prestige column. We are trying to predict the admission rate based on the prestige of the school, and we will have to get rid of the prestige level 1 column to prevent collinearity. Then we can do logistic regression using the statsmodels logit function. The output of this function will show the coefficients, how well they fit, overall fit, and some other statistics that will help describe the model. Then you can look at the confidence interval and determine the relationship between the variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 14. What is your hypothesis? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: There will be an association between grad school admission rates and the prestige of undergraduate schools. Specifically, the admission rate will be higher for students who went to more prestigious schools. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Review Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is test error and train error?\n",
    "2. What are ways to mitigate a situation where you have low train error but high test error?\n",
    "3. What are some of the parameters you can tweak to get a better fit in ordinary linear regression?\n",
    "4. What package would you use to explore these parameters easily and find the best model?\n",
    "5. What is the difference between Lasso and Ridge regression?\n",
    "    6a. When do you use which?\n",
    "6. Bonus: Explore alternatives to dropping obervations with missing data\n",
    "\n",
    "Advanced Bonus:\n",
    "1. What makes Lasso regression do what it does to the coefficients?\n",
    "2. How do you deal with multi-colinearity when performing linear regression?\n",
    "3. What is the \"distance\" formula in KNN? I.e. how does KNN account for distance to the k neighbours when predicting the class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
